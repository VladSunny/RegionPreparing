{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö –®–ü–û–†–ê –ü–û –ú–û–î–ï–õ–Ø–ú: –ß—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏ –∫–æ–≥–¥–∞\n",
    "\n",
    "–ë—ã—Å—Ç—Ä—ã–π –≥–∞–π–¥ –ø–æ –≤—Å–µ–º –º–æ–¥–µ–ª—è–º, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø—Ä–∏–≥–æ–¥–∏—Ç—å—Å—è –Ω–∞ –æ–ª–∏–º–ø–∏–∞–¥–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "üèÜ –†–ï–ô–¢–ò–ù–ì –ú–û–î–ï–õ–ï–ô –î–õ–Ø –¢–ê–ë–õ–ò–ß–ù–´–• –î–ê–ù–ù–´–•\n",
    "\n",
    "| –ú–µ—Å—Ç–æ | –ú–æ–¥–µ–ª—å | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |\n",
    "|-------|--------|--------------------|\n",
    "| ü•á | **CatBoost** | –ü–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞. –õ—É—á—à–∏–π –≤—ã–±–æ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é |\n",
    "| ü•à | **LightGBM** | –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ (>100k —Å—Ç—Ä–æ–∫), –Ω—É–∂–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å |\n",
    "| ü•â | **XGBoost** | –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞, –µ—Å–ª–∏ –ø–µ—Ä–≤—ã–µ –¥–≤–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç |\n",
    "| 4 | **RandomForest** | –ù—É–∂–Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å, –º–µ–Ω—å—à–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ |\n",
    "| 5 | **LogisticRegression** | –õ–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å |\n",
    "| 6 | **KNN** | –ó–∞–¥–∞—á–∏ –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é/–ø–æ—Ö–æ–∂–µ—Å—Ç—å |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "‚ö†Ô∏è –í–ê–ñ–ù–û: –ú–æ–¥–µ–ª—å –∏–∑ –∫–æ—Ä–æ–±–∫–∏ –ª—É—á—à–µ, —á–µ–º —Å —Ä–∞–Ω–¥–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏!\n",
    "\n",
    "**–¢–∏–ø–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞:** –≤–∑—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏–ª–∏ –ø–æ—Å—Ç–∞–≤–∏—Ç—å \"–∫—Ä–∞—Å–∏–≤—ã–µ\" —á–∏—Å–ª–∞.\n",
    "\n",
    "```python\n",
    "# ‚ùå –ü–õ–û–•–û ‚Äî —Ä–∞–Ω–¥–æ–º–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.1)\n",
    "\n",
    "# ‚úÖ –•–û–†–û–®–û ‚Äî –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "model = CatBoostClassifier()  # –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫!\n",
    "```\n",
    "\n",
    "**–ü–æ—á–µ–º—É —Ç–∞–∫?**\n",
    "- –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ CatBoost/LightGBM –≥–æ–¥–∞–º–∏ –ø–æ–¥–±–∏—Ä–∞–ª–∏ –¥–µ—Ñ–æ–ª—Ç—ã\n",
    "- –î–µ—Ñ–æ–ª—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø–æ–¥ \"—Å—Ä–µ–¥–Ω—é—é\" –∑–∞–¥–∞—á—É\n",
    "- –†–∞–Ω–¥–æ–º–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–≥—É—Ç —Å–ª–æ–º–∞—Ç—å –º–æ–¥–µ–ª—å\n",
    "\n",
    "**–ö–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã?**\n",
    "1. –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–π –¥–µ—Ñ–æ–ª—Ç\n",
    "2. –ï—Å–ª–∏ –Ω–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç ‚Äî –¥–µ–ª–∞–π **–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥–±–æ—Ä** (—Å–º. –Ω–∏–∂–µ)\n",
    "3. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ —Å—Ç–∞–≤—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã \"–Ω–∞ –≥–ª–∞–∑\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "CATBOOST (—Ç–≤–æ–π –≥–ª–∞–≤–Ω—ã–π –¥—Ä—É–≥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "# === –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø ===\n",
    "# –î–µ—Ñ–æ–ª—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç!\n",
    "model = CatBoostClassifier(verbose=100, random_seed=42, cat_features=cat_features)\n",
    "\n",
    "# === –†–ï–ì–†–ï–°–°–ò–Ø ===\n",
    "model_reg = CatBoostRegressor(verbose=100, random_seed=42, cat_features=cat_features)\n",
    "\n",
    "# –ï—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ MAE (–Ω–µ RMSE):\n",
    "# model_reg = CatBoostRegressor(loss_function='MAE', verbose=100, cat_features=cat_features)\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "predictions = model.predict(X_test)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]  # –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã CatBoost:**\n",
    "\n",
    "| –ü—Ä–æ–±–ª–µ–º–∞ | –ß—Ç–æ –¥–µ–ª–∞—Ç—å |\n",
    "|----------|------------|\n",
    "| –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (train >> val) | –£–º–µ–Ω—å—à–∏ depth (4-5), —É–≤–µ–ª–∏—á—å l2_leaf_reg (5-10) |\n",
    "| –ù–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ (train ‚âà val, –æ–±–∞ –ø–ª–æ—Ö–∏–µ) | –£–≤–µ–ª–∏—á—å iterations, —É–º–µ–Ω—å—à–∏ learning_rate |\n",
    "| –û—á–µ–Ω—å –¥–æ–ª–≥–æ —É—á–∏—Ç—Å—è | –£–≤–µ–ª–∏—á—å learning_rate (0.1), —É–º–µ–Ω—å—à–∏ iterations |\n",
    "| –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã | –î–æ–±–∞–≤—å class_weights='Balanced' |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "LIGHTGBM (–¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "# === –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø ===\n",
    "# –î–µ—Ñ–æ–ª—Ç\n",
    "model = LGBMClassifier(random_state=42, verbose=-1)\n",
    "\n",
    "# === –†–ï–ì–†–ï–°–°–ò–Ø ===\n",
    "model_reg = LGBMRegressor(random_state=42, verbose=-1)\n",
    "\n",
    "# –ï—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ MAE:\n",
    "# model_reg = LGBMRegressor(objective='mae', verbose=-1)\n",
    "\n",
    "# –í–ê–ñ–ù–û: LightGBM –Ω–µ —É–º–µ–µ—Ç –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–∞–∫ CatBoost!\n",
    "# –ù—É–∂–Ω–æ –∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å: LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LightGBM:**\n",
    "\n",
    "| –ü—Ä–æ–±–ª–µ–º–∞ | –ß—Ç–æ –¥–µ–ª–∞—Ç—å |\n",
    "|----------|------------|\n",
    "| –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ | –£–º–µ–Ω—å—à–∏ num_leaves (15-20), —É–≤–µ–ª–∏—á—å min_child_samples (50-100) |\n",
    "| –ù–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ | –£–≤–µ–ª–∏—á—å num_leaves (50-100), —É–≤–µ–ª–∏—á—å n_estimators |\n",
    "| –î–æ–ª–≥–æ —É—á–∏—Ç—Å—è | –£–º–µ–Ω—å—à–∏ n_estimators, —É–≤–µ–ª–∏—á—å learning_rate |\n",
    "| –®—É–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ | –£–≤–µ–ª–∏—á—å reg_alpha –∏ reg_lambda (0.1-1) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "XGBOOST (–∫–ª–∞—Å—Å–∏–∫–∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# === –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø ===\n",
    "# –î–µ—Ñ–æ–ª—Ç\n",
    "model = XGBClassifier(random_state=42, verbosity=0)\n",
    "\n",
    "# === –†–ï–ì–†–ï–°–°–ò–Ø ===\n",
    "model_reg = XGBRegressor(random_state=42, verbosity=0)\n",
    "\n",
    "# –ï—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ MAE:\n",
    "# model_reg = XGBRegressor(objective='reg:absoluteerror', verbosity=0)\n",
    "\n",
    "# –í–ê–ñ–ù–û: XGBoost –Ω–µ —É–º–µ–µ—Ç –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏!\n",
    "# –ù—É–∂–Ω–æ –∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å: LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã XGBoost:**\n",
    "\n",
    "| –ü—Ä–æ–±–ª–µ–º–∞ | –ß—Ç–æ –¥–µ–ª–∞—Ç—å |\n",
    "|----------|------------|\n",
    "| –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ | –£–º–µ–Ω—å—à–∏ max_depth (3-5), —É–≤–µ–ª–∏—á—å reg_alpha/reg_lambda |\n",
    "| –ù–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ | –£–≤–µ–ª–∏—á—å n_estimators, —É–º–µ–Ω—å—à–∏ learning_rate |\n",
    "| –î–æ–ª–≥–æ —É—á–∏—Ç—Å—è | –£–º–µ–Ω—å—à–∏ n_estimators, —É–≤–µ–ª–∏—á—å learning_rate (0.1-0.3) |\n",
    "| –í—ã–±—Ä–æ—Å—ã –≤ –¥–∞–Ω–Ω—ã—Ö | –ò—Å–ø–æ–ª—å–∑—É–π objective='reg:pseudohubererror' |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "RANDOM FOREST (—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# === –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø ===\n",
    "# –î–µ—Ñ–æ–ª—Ç\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ–¥–∫—Ä—É—Ç–∏—Ç—å:\n",
    "# model = RandomForestClassifier(\n",
    "#     n_estimators=300,       # –¥–µ—Ñ–æ–ª—Ç: 100\n",
    "#     max_depth=10,           # –¥–µ—Ñ–æ–ª—Ç: None (–¥–æ –∫–æ–Ω—Ü–∞)\n",
    "#     min_samples_split=5,    # –¥–µ—Ñ–æ–ª—Ç: 2\n",
    "#     min_samples_leaf=2,     # –¥–µ—Ñ–æ–ª—Ç: 1\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# === –†–ï–ì–†–ï–°–°–ò–Ø ===\n",
    "model_reg = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# –í–ê–ñ–ù–û: RandomForest –Ω–µ —É–º–µ–µ—Ç –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏!\n",
    "# –ù—É–∂–Ω–æ –∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å: LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã RandomForest:**\n",
    "\n",
    "| –ü—Ä–æ–±–ª–µ–º–∞ | –ß—Ç–æ –¥–µ–ª–∞—Ç—å |\n",
    "|----------|------------|\n",
    "| –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ | –£–º–µ–Ω—å—à–∏ max_depth (5-10), —É–≤–µ–ª–∏—á—å min_samples_leaf (5-10) |\n",
    "| –ù–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ | –£–≤–µ–ª–∏—á—å n_estimators (300-500), —É–±–µ—Ä–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ max_depth |\n",
    "| –î–æ–ª–≥–æ —É—á–∏—Ç—Å—è | –£–º–µ–Ω—å—à–∏ n_estimators (50-100), —É–º–µ–Ω—å—à–∏ max_depth |\n",
    "| –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã | class_weight='balanced' |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "LOGISTIC REGRESSION (–¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–¥–∞—á)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# –í–ê–ñ–ù–û: –õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¢–†–ï–ë–£–Æ–¢ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è!\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø ===\n",
    "# –î–µ—Ñ–æ–ª—Ç\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ–¥–∫—Ä—É—Ç–∏—Ç—å:\n",
    "# model = LogisticRegression(\n",
    "#     C=1.0,              # –¥–µ—Ñ–æ–ª—Ç: 1.0 (–æ–±—Ä–∞—Ç–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)\n",
    "#     penalty='l2',       # –¥–µ—Ñ–æ–ª—Ç: 'l2'\n",
    "#     max_iter=1000,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# === –†–ï–ì–†–ï–°–°–ò–Ø ===\n",
    "model_ridge = Ridge()   # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
    "model_lasso = Lasso()   # L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (–æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LogisticRegression:**\n",
    "\n",
    "| –ü—Ä–æ–±–ª–µ–º–∞ | –ß—Ç–æ –¥–µ–ª–∞—Ç—å |\n",
    "|----------|------------|\n",
    "| –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ | –£–º–µ–Ω—å—à–∏ C (0.01-0.1), —É—Å–∏–ª–∏—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é |\n",
    "| –ù–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ | –£–≤–µ–ª–∏—á—å C (10-100), –æ—Å–ª–∞–±–∏—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é |\n",
    "| –ú–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | –ò—Å–ø–æ–ª—å–∑—É–π penalty='l1' —Å solver='saga' (–æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤) |\n",
    "| –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã | class_weight='balanced' |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "KNN (–¥–ª—è –∑–∞–¥–∞—á –Ω–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç—å)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# –í–ê–ñ–ù–û: KNN –¢–†–ï–ë–£–ï–¢ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è!\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø ===\n",
    "# –î–µ—Ñ–æ–ª—Ç (k=5)\n",
    "model = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ–¥–∫—Ä—É—Ç–∏—Ç—å:\n",
    "# model = KNeighborsClassifier(\n",
    "#     n_neighbors=5,      # –¥–µ—Ñ–æ–ª—Ç: 5 (–æ–±—ã—á–Ω–æ 3-15)\n",
    "#     weights='distance', # –¥–µ—Ñ–æ–ª—Ç: 'uniform'\n",
    "#     metric='euclidean', # –¥–µ—Ñ–æ–ª—Ç: 'minkowski'\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# === –†–ï–ì–†–ï–°–°–ò–Ø ===\n",
    "model_reg = KNeighborsRegressor(n_jobs=-1)\n",
    "\n",
    "# –ü–æ–¥–±–æ—Ä k —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–±–æ—Ä:\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# for k in range(3, 20):\n",
    "#     model = KNeighborsClassifier(n_neighbors=k)\n",
    "#     scores = cross_val_score(model, X_scaled, y, cv=5)\n",
    "#     print(f'k={k}: {scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã KNN:**\n",
    "\n",
    "| –ü—Ä–æ–±–ª–µ–º–∞ | –ß—Ç–æ –¥–µ–ª–∞—Ç—å |\n",
    "|----------|------------|\n",
    "| –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ | –£–≤–µ–ª–∏—á—å n_neighbors (15-30) |\n",
    "| –ù–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ | –£–º–µ–Ω—å—à–∏ n_neighbors (3-5) |\n",
    "| –ú–Ω–æ–≥–æ —à—É–º–∞ | weights='distance' (–±–ª–∏–∂–Ω–∏–µ —Å–æ—Å–µ–¥–∏ –≤–∞–∂–Ω–µ–µ) |\n",
    "| –†–∞–∑–Ω—ã–π –º–∞—Å—à—Ç–∞–± –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ StandardScaler! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø (–¥–ª—è –∑–∞–¥–∞—á –±–µ–∑ –º–µ—Ç–æ–∫)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === K-MEANS ===\n",
    "# –ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init='auto')\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# === DBSCAN (–Ω–µ –Ω—É–∂–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤) ===\n",
    "# –î–µ—Ñ–æ–ª—Ç\n",
    "dbscan = DBSCAN()  # eps=0.5, min_samples=5\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ–¥–∫—Ä—É—Ç–∏—Ç—å:\n",
    "# dbscan = DBSCAN(\n",
    "#     eps=0.5,            # —Ä–∞–¥–∏—É—Å —Å–æ—Å–µ–¥—Å—Ç–≤–∞\n",
    "#     min_samples=5       # –º–∏–Ω. —Ç–æ—á–µ–∫ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:**\n",
    "\n",
    "| –ú–æ–¥–µ–ª—å | –ü—Ä–æ–±–ª–µ–º–∞ | –ß—Ç–æ –¥–µ–ª–∞—Ç—å |\n",
    "|--------|----------|------------|\n",
    "| KMeans | –ü–ª–æ—Ö–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã | –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–µ n_clusters, –ø—Ä–æ–≤–µ—Ä—å –º–µ—Ç–æ–¥ –ª–æ–∫—Ç—è |\n",
    "| KMeans | –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç | –£–≤–µ–ª–∏—á—å n_init (20-30) |\n",
    "| DBSCAN | –í—Å—ë –≤ –æ–¥–Ω–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ | –£–º–µ–Ω—å—à–∏ eps –∏–ª–∏ —É–≤–µ–ª–∏—á—å min_samples |\n",
    "| DBSCAN | –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –º–µ–ª–∫–∏—Ö | –£–≤–µ–ª–∏—á—å eps –∏–ª–∏ —É–º–µ–Ω—å—à–∏ min_samples |\n",
    "| –õ—é–±–∞—è | –°—Ç—Ä–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã | –ü—Ä–æ–≤–µ—Ä—å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# –ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è + —Å–∏–ª—É—ç—Ç\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_scaled, labels)) # advanced\n",
    "\n",
    "# –ì—Ä–∞—Ñ–∏–∫–∏\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(K_range, inertias, 'bo-')\n",
    "ax1.set_xlabel('–ß–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è')\n",
    "\n",
    "ax2.plot(K_range, silhouettes, 'ro-')\n",
    "ax2.set_xlabel('–ß–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')\n",
    "ax2.set_ylabel('Silhouette')\n",
    "ax2.set_title('Silhouette Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'–õ—É—á—à–∏–π k –ø–æ silhouette: {K_range[silhouettes.index(max(silhouettes))]}') # advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–ú–ï–¢–†–ò–ö–ò: –ß—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    \n",
    "    # –†–µ–≥—Ä–µ—Å—Å–∏—è\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# === –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø ===\n",
    "print('Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Precision:', precision_score(y_true, y_pred))\n",
    "print('Recall:', recall_score(y_true, y_pred))\n",
    "print('F1:', f1_score(y_true, y_pred))\n",
    "print('ROC-AUC:', roc_auc_score(y_true, y_proba))\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# === –†–ï–ì–†–ï–°–°–ò–Ø ===\n",
    "print('MAE:', mean_absolute_error(y_true, y_pred))\n",
    "print('MSE:', mean_squared_error(y_true, y_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "print('R2:', r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–∞–∫—É—é –º–µ—Ç—Ä–∏–∫—É –≤—ã–±—Ä–∞—Ç—å:**\n",
    "\n",
    "| –ó–∞–¥–∞—á–∞ | –ú–µ—Ç—Ä–∏–∫–∞ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |\n",
    "|--------|---------|--------------------|\n",
    "| –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è | ROC-AUC | –ü–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ |\n",
    "| –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã | F1, Precision, Recall | –í–∞–∂–Ω–µ–µ –Ω–∞–π—Ç–∏ —Ä–µ–¥–∫–∏–π –∫–ª–∞—Å—Å |\n",
    "| –ú—É–ª—å—Ç–∏–∫–ª–∞—Å—Å | Accuracy, macro-F1 | –í—Å–µ –∫–ª–∞—Å—Å—ã –≤–∞–∂–Ω—ã |\n",
    "| –†–µ–≥—Ä–µ—Å—Å–∏—è (–æ–±—ã—á–Ω–∞—è) | RMSE | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é |\n",
    "| –†–µ–≥—Ä–µ—Å—Å–∏—è (–≤—ã–±—Ä–æ—Å—ã) | MAE | –£—Å—Ç–æ–π—á–∏–≤–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–ö–û–î–ò–†–û–í–ê–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# === LABEL ENCODING (–¥–ª—è –¥–µ—Ä–µ–≤—å–µ–≤) ===\n",
    "le = LabelEncoder()\n",
    "train['category_encoded'] = le.fit_transform(train['category'])\n",
    "test['category_encoded'] = le.transform(test['category'])\n",
    "\n",
    "# === ONE-HOT ENCODING (–¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π) ===\n",
    "train_encoded = pd.get_dummies(train, columns=['category'])\n",
    "test_encoded = pd.get_dummies(test, columns=['category'])\n",
    "\n",
    "# –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ (–µ—Å–ª–∏ –≤ test –Ω–µ—Ç –∫–∞–∫–∏—Ö-—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π)\n",
    "train_encoded, test_encoded = train_encoded.align(test_encoded, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# === TARGET ENCODING (–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π) ===\n",
    "# –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–∞—Ä–≥–µ—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n",
    "target_means = train.groupby('category')['target'].mean()\n",
    "train['category_target_enc'] = train['category'].map(target_means)\n",
    "test['category_target_enc'] = test['category'].map(target_means)\n",
    "# –í–ê–ñ–ù–û: –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–ê–ù–°–ê–ú–ë–õ–ò (–∫–æ–≥–¥–∞ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ –º–∞–ª–æ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –ü–†–û–°–¢–û–ï –£–°–†–ï–î–ù–ï–ù–ò–ï ===\n",
    "pred1 = model1.predict_proba(X_test)[:, 1]\n",
    "pred2 = model2.predict_proba(X_test)[:, 1]\n",
    "pred3 = model3.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# –°—Ä–µ–¥–Ω–µ–µ\n",
    "ensemble_pred = (pred1 + pred2 + pred3) / 3\n",
    "\n",
    "# –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ\n",
    "ensemble_pred = 0.5 * pred1 + 0.3 * pred2 + 0.2 * pred3\n",
    "\n",
    "# === –ì–û–õ–û–°–û–í–ê–ù–ò–ï ===\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('cat', CatBoostClassifier(verbose=0)),\n",
    "        ('lgbm', LGBMClassifier(verbose=-1)),\n",
    "        ('rf', RandomForestClassifier())\n",
    "    ],\n",
    "    voting='soft'  # 'hard' = –ø–æ –∫–ª–∞—Å—Å–∞–º, 'soft' = –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º\n",
    ")\n",
    "voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–ü–û–î–ë–û–† –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í: –ö–∞–∫ –¥–µ–ª–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ\n",
    "\n",
    "**–ü—Ä–∞–≤–∏–ª–æ:** –õ–∏–±–æ –¥–µ—Ñ–æ–ª—Ç, –ª–∏–±–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥–±–æ—Ä. –ù–∏–∫–∞–∫–∏—Ö \"–Ω–∞ –≥–ª–∞–∑\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–°–ø–æ—Å–æ–± 1: GridSearchCV (–ø–µ—Ä–µ–±–æ—Ä –ø–æ —Å–µ—Ç–∫–µ)**\n",
    "\n",
    "–ü–ª—é—Å—ã: –ü—Ä–æ—Å—Ç–æ–π, –Ω–∞–¥—ë–∂–Ω—ã–π\n",
    "–ú–∏–Ω—É—Å—ã: –î–æ–ª–≥–∏–π –ø—Ä–∏ –±–æ–ª—å—à–æ–º —á–∏—Å–ª–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# –°–µ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –ø–µ—Ä–µ–±–æ—Ä–∞\n",
    "param_grid = {\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'iterations': [500, 1000]\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(verbose=0, random_seed=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=3,              # 3-fold –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "    scoring='roc_auc', # –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "    n_jobs=-1,         # –≤—Å–µ —è–¥—Ä–∞\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search.best_params_}')\n",
    "print(f'–õ—É—á—à–∏–π —Å–∫–æ—Ä: {grid_search.best_score_:.4f}')\n",
    "\n",
    "# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–°–ø–æ—Å–æ–± 2: –†—É—á–Ω–æ–π –ø–µ—Ä–µ–±–æ—Ä (–±—ã—Å—Ç—Ä—ã–π)**\n",
    "\n",
    "–ö–æ–≥–¥–∞ –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –ø–æ–ª–Ω—ã–π –ø–æ–∏—Å–∫ ‚Äî –ø–æ–ø—Ä–æ–±—É–π –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# –ù–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑—É–º–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π\n",
    "configs = [\n",
    "    {'iterations': 1000, 'depth': 6, 'learning_rate': 0.05},  # –±–∞–∑–æ–≤–∞—è\n",
    "    {'iterations': 2000, 'depth': 4, 'learning_rate': 0.03},  # –≥–ª—É–±–∂–µ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ\n",
    "    {'iterations': 500, 'depth': 8, 'learning_rate': 0.1},    # –±—ã—Å—Ç—Ä–µ–µ, –≥–ª—É–±–∂–µ\n",
    "    {},  # –¥–µ—Ñ–æ–ª—Ç!\n",
    "]\n",
    "\n",
    "best_score = 0\n",
    "best_config = None\n",
    "\n",
    "for config in configs:\n",
    "    model = CatBoostClassifier(**config, verbose=0, random_seed=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "    mean_score = scores.mean()\n",
    "    print(f'{config}: {mean_score:.4f}')\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_config = config\n",
    "\n",
    "print(f'\\n–õ—É—á—à–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {best_config}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–∞–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–±–∏—Ä–∞—Ç—å –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å:**\n",
    "\n",
    "| –ú–æ–¥–µ–ª—å | –ì–ª–∞–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã | –í—Ç–æ—Ä–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–µ |\n",
    "|--------|-------------------|----------------|\n",
    "| CatBoost | depth, learning_rate, iterations | l2_leaf_reg, random_strength |\n",
    "| LightGBM | num_leaves, learning_rate, n_estimators | min_child_samples, reg_alpha |\n",
    "| XGBoost | max_depth, learning_rate, n_estimators | reg_alpha, reg_lambda |\n",
    "| RandomForest | n_estimators, max_depth | min_samples_split, max_features |\n",
    "| KNN | n_neighbors | weights, metric |\n",
    "\n",
    "**–°–æ–≤–µ—Ç –¥–ª—è –æ–ª–∏–º–ø–∏–∞–¥—ã:**\n",
    "1. –ù–∞—á–Ω–∏ —Å –¥–µ—Ñ–æ–ª—Ç–∞ ‚Äî —ç—Ç–æ —É–∂–µ —Ö–æ—Ä–æ—à–æ\n",
    "2. –ï—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º—è ‚Äî —Å–¥–µ–ª–∞–π —Ä—É—á–Ω–æ–π –ø–µ—Ä–µ–±–æ—Ä 3-5 –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π\n",
    "3. GridSearchCV —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –º–∞–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–ë–´–°–¢–†–´–ô –°–ü–†–ê–í–û–ß–ù–ò–ö\n",
    "\n",
    "**–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω—É–∂–Ω–æ –¥–ª—è:**\n",
    "- KNN ‚úÖ\n",
    "- LogisticRegression ‚úÖ\n",
    "- SVM ‚úÖ\n",
    "- –ù–µ–π—Ä–æ—Å–µ—Ç–∏ ‚úÖ\n",
    "- CatBoost ‚ùå\n",
    "- LightGBM ‚ùå\n",
    "- RandomForest ‚ùå\n",
    "\n",
    "**–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω—É–∂–Ω–æ –∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è:**\n",
    "- CatBoost ‚ùå (—Å–∞–º —É–º–µ–µ—Ç)\n",
    "- LightGBM ‚úÖ (LabelEncoder)\n",
    "- RandomForest ‚úÖ (LabelEncoder)\n",
    "- LogisticRegression ‚úÖ (OneHot)\n",
    "- KNN ‚úÖ (OneHot –∏–ª–∏ LabelEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
