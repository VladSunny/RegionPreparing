{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß† –ö–ê–ö –î–£–ú–ê–¢–¨, –ö–û–ì–î–ê –°–ú–û–¢–†–ò–®–¨ –ù–ê –î–ê–ù–ù–´–ï\n",
    "\n",
    "–≠—Ç–æ –Ω–µ —à–ø–æ—Ä–∞ –ø–æ –∫–æ–º–∞–Ω–¥–∞–º ‚Äî —ç—Ç–æ —à–ø–æ—Ä–∞ –ø–æ **–º—ã—à–ª–µ–Ω–∏—é**.\n",
    "\n",
    "–¶–µ–ª—å: –Ω–∞—É—á–∏—Ç—å—Å—è –∑–∞–¥–∞–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –¥–∞–Ω–Ω—ã–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–ü–ï–†–í–´–ï 5 –ú–ò–ù–£–¢: –ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö?\n",
    "\n",
    "**–í–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∑–∞–¥–∞—Ç—å —Å–µ–±–µ:**\n",
    "\n",
    "1. **–ß—Ç–æ —è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é?** (—Ç–∞—Ä–≥–µ—Ç)\n",
    "2. **–°–∫–æ–ª—å–∫–æ —É –º–µ–Ω—è –¥–∞–Ω–Ω—ã—Ö?** (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–ª—è ML?)\n",
    "3. **–ö–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –µ—Å—Ç—å?** (—á–∏—Å–ª–∞, –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –¥–∞—Ç—ã, —Ç–µ–∫—Å—Ç?)\n",
    "4. **–ï—Å—Ç—å –ª–∏ –ø—Ä–æ–ø—É—Å–∫–∏?** (–º–Ω–æ–≥–æ –ª–∏? –≤ –∫–∞–∫–∏—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö?)\n",
    "5. **–ï—Å—Ç—å –ª–∏ –æ—á–µ–≤–∏–¥–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã?** (–¥—É–±–ª–∏–∫–∞—Ç—ã, —Å—Ç—Ä–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# === –ü–ï–†–í–´–ô –í–ó–ì–õ–Ø–î ===\n",
    "print('üìä –†–ê–ó–ú–ï–†–´:')\n",
    "print(f'Train: {train.shape[0]} —Å—Ç—Ä–æ–∫, {train.shape[1]} –∫–æ–ª–æ–Ω–æ–∫')\n",
    "print(f'Test: {test.shape[0]} —Å—Ç—Ä–æ–∫, {test.shape[1]} –∫–æ–ª–æ–Ω–æ–∫')\n",
    "print()\n",
    "\n",
    "print('üëÄ –ü–ï–†–í–´–ï –°–¢–†–û–ö–ò:')\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –ß–¢–û –ó–ê –î–ê–ù–ù–´–ï? ===\n",
    "print('üìã –¢–ò–ü–´ –î–ê–ù–ù–´–•:')\n",
    "print(train.dtypes)\n",
    "print()\n",
    "\n",
    "print('üî¢ –ß–ò–°–õ–û–í–´–ï –ö–û–õ–û–ù–ö–ò:', train.select_dtypes(include=['int64', 'float64']).columns.tolist())\n",
    "print('üìù –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–ï:', train.select_dtypes(include=['object']).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –ü–†–û–ü–£–°–ö–ò ===\n",
    "print('‚ùì –ü–†–û–ü–£–°–ö–ò:')\n",
    "missing = train.isnull().sum()\n",
    "missing_pct = (missing / len(train) * 100).round(1)\n",
    "missing_df = pd.DataFrame({'–ü—Ä–æ–ø—É—Å–∫–æ–≤': missing, '%': missing_pct})\n",
    "print(missing_df[missing_df['–ü—Ä–æ–ø—É—Å–∫–æ–≤'] > 0].sort_values('%', ascending=False))\n",
    "\n",
    "if missing.sum() == 0:\n",
    "    print('–ü—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ—Ç! üéâ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–°–ú–û–¢–†–ò–ú –ù–ê –¢–ê–†–ì–ï–¢: –≠—Ç–æ –ø–µ—Ä–≤–æ–µ, —á—Ç–æ –Ω—É–∂–Ω–æ –ø–æ–Ω—è—Ç—å!\n",
    "\n",
    "**–í–æ–ø—Ä–æ—Å—ã:**\n",
    "- –≠—Ç–æ **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è** –∏–ª–∏ **—Ä–µ–≥—Ä–µ—Å—Å–∏—è**?\n",
    "- –ï—Å–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ‚Äî **—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã –ª–∏ –∫–ª–∞—Å—Å—ã**?\n",
    "- –ï—Å–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî **–∫–∞–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ** —É —Ç–∞—Ä–≥–µ—Ç–∞? (–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ? –µ—Å—Ç—å –≤—ã–±—Ä–æ—Å—ã?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'target'  # <-- –ü–û–ú–ï–ù–Ø–ô\n",
    "\n",
    "print('üéØ –¢–ê–†–ì–ï–¢:')\n",
    "print(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {train[TARGET].nunique()}')\n",
    "print()\n",
    "\n",
    "# –ï—Å–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (–º–∞–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)\n",
    "if train[TARGET].nunique() <= 10:\n",
    "    print('–≠—Ç–æ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø')\n",
    "    print('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:')\n",
    "    print(train[TARGET].value_counts())\n",
    "    print()\n",
    "    print('–í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö:')\n",
    "    print((train[TARGET].value_counts(normalize=True) * 100).round(1))\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞\n",
    "    balance = train[TARGET].value_counts(normalize=True).min()\n",
    "    if balance < 0.1:\n",
    "        print('\\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ö–ª–∞—Å—Å—ã —Å–∏–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã!')\n",
    "        print('–ü–æ–¥—É–º–∞–π –æ class_weight –∏–ª–∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ')\n",
    "else:\n",
    "    print('–≠—Ç–æ –†–ï–ì–†–ï–°–°–ò–Ø')\n",
    "    print(train[TARGET].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∞—Ä–≥–µ—Ç–∞\n",
    "if train[TARGET].nunique() <= 10:\n",
    "    train[TARGET].value_counts().plot(kind='bar')\n",
    "    plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤')\n",
    "else:\n",
    "    train[TARGET].hist(bins=50)\n",
    "    plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞—Ä–≥–µ—Ç–∞')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–°–ú–û–¢–†–ò–ú –ù–ê –ü–†–ò–ó–ù–ê–ö–ò: –ò—â–µ–º –ø–æ–ª–µ–∑–Ω–æ–µ –∏ –ø—Ä–æ–±–ª–µ–º–Ω–æ–µ\n",
    "\n",
    "**–ß—Ç–æ –∏—Å–∫–∞—Ç—å:**\n",
    "\n",
    "- **–í—ã–±—Ä–æ—Å—ã** ‚Äî –µ—Å—Ç—å –ª–∏ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è?\n",
    "- **–ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏** ‚Äî –∫–æ–ª–æ–Ω–∫–∏ —Å –æ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (–±–µ—Å–ø–æ–ª–µ–∑–Ω—ã)\n",
    "- **–í—ã—Å–æ–∫–∞—è –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å** ‚Äî –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å 1000+ –∑–Ω–∞—á–µ–Ω–∏–π (–º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–æ–±–ª–µ–º–æ–π)\n",
    "- **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º** ‚Äî –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–∞–∂–Ω—ã?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ß–ò–°–õ–û–í–´–ú ===\n",
    "print('üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ß–ò–°–õ–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í:')\n",
    "display(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –ü–†–û–í–ï–†–ö–ê –ù–ê –ü–†–û–ë–õ–ï–ú–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò ===\n",
    "\n",
    "print('üö® –ü–†–û–í–ï–†–ö–ê –ù–ê –ü–†–û–ë–õ–ï–ú–´:')\n",
    "print()\n",
    "\n",
    "# 1. –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "const_cols = [c for c in train.columns if train[c].nunique() == 1]\n",
    "if const_cols:\n",
    "    print(f'‚ùå –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (—É–¥–∞–ª–∏—Ç—å!): {const_cols}')\n",
    "else:\n",
    "    print('‚úÖ –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –Ω–µ—Ç')\n",
    "\n",
    "# 2. –ü–æ—á—Ç–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ (>99% –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ)\n",
    "almost_const = []\n",
    "for c in train.columns:\n",
    "    if train[c].value_counts(normalize=True).iloc[0] > 0.99:\n",
    "        almost_const.append(c)\n",
    "if almost_const:\n",
    "    print(f'‚ö†Ô∏è –ü–æ—á—Ç–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ: {almost_const}')\n",
    "\n",
    "# 3. –í—ã—Å–æ–∫–∞—è –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å\n",
    "high_card = [c for c in train.select_dtypes(include=['object']).columns \n",
    "             if train[c].nunique() > 100]\n",
    "if high_card:\n",
    "    print(f'‚ö†Ô∏è –í—ã—Å–æ–∫–∞—è –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {high_card}')\n",
    "    print('   (–º–Ω–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π ‚Äî –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–±–ª–µ–º–æ–π)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –ö–û–†–†–ï–õ–Ø–¶–ò–ò –° –¢–ê–†–ì–ï–¢–û–ú ===\n",
    "# –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "if train[TARGET].dtype in ['int64', 'float64']:\n",
    "    correlations = train.corr(numeric_only=True)[TARGET].drop(TARGET).sort_values(key=abs, ascending=False)\n",
    "    print('üîó –ö–û–†–†–ï–õ–Ø–¶–ò–ò –° –¢–ê–†–ì–ï–¢–û–ú (—Ç–æ–ø-10):')\n",
    "    print(correlations.head(10))\n",
    "    print()\n",
    "    print('üí° –í–´–í–û–î: –≠—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤–∞–∂–Ω—ã –¥–ª—è –º–æ–¥–µ–ª–∏')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–ò–©–ï–ú –°–í–Ø–ó–ò: –ö–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–≤—è–∑–∞–Ω—ã –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º?\n",
    "\n",
    "**–ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ:**\n",
    "- –ù–∞–π—Ç–∏ **–ª–∏–∫–∏** (data leakage) ‚Äî –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ \"–ø–æ–¥—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç\" –≤ –æ—Ç–≤–µ—Ç\n",
    "- –ü–æ–Ω—è—Ç—å, –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–∂–Ω–æ **–æ–±—ä–µ–¥–∏–Ω–∏—Ç—å**\n",
    "- –ù–∞–π—Ç–∏ **–º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å** ‚Äî –∫–æ–≥–¥–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥—É–±–ª–∏—Ä—É—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = train.select_dtypes(include=['int64', 'float64']).corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–ú –í–´–®–ï\n",
    "# correlations = train.corr(numeric_only=True)[TARGET].drop(TARGET).sort_values(key=abs, ascending=False)\n",
    "\n",
    "# === –ü–û–ò–°–ö –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–• –õ–ò–ö–û–í ===\n",
    "\n",
    "if train[TARGET].dtype in ['int64', 'float64']:\n",
    "    high_corr = correlations[abs(correlations) > 0.9]\n",
    "    if len(high_corr) > 0:\n",
    "        print('üö® –í–ù–ò–ú–ê–ù–ò–ï! –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ç–∞—Ä–≥–µ—Ç–æ–º:')\n",
    "        print(high_corr)\n",
    "        print()\n",
    "        print('–≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å:')\n",
    "        print('1. DATA LEAKAGE ‚Äî –ø—Ä–∏–∑–Ω–∞–∫ \"–∑–Ω–∞–µ—Ç\" –æ—Ç–≤–µ—Ç (–ø–ª–æ—Ö–æ!)')\n",
    "        print('2. –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–π –ø—Ä–∏–∑–Ω–∞–∫ (—Ö–æ—Ä–æ—à–æ, –Ω–æ –ø—Ä–æ–≤–µ—Ä—å)')\n",
    "        print()\n",
    "        print('–ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å: –ø–æ—Å–º–æ—Ç—Ä–∏, –º–æ–≥ –ª–∏ —ç—Ç–æ—Ç –ø—Ä–∏–∑–Ω–∞–∫ –±—ã—Ç—å –∏–∑–≤–µ—Å—Ç–µ–Ω –î–û —Ç–æ–≥–æ, –∫–∞–∫ —Å—Ç–∞–ª –∏–∑–≤–µ—Å—Ç–µ–Ω —Ç–∞—Ä–≥–µ—Ç?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–í–´–ë–†–û–°–´: –ö–∞–∫ –∏—Ö –Ω–∞–π—Ç–∏ –∏ —á—Ç–æ —Å –Ω–∏–º–∏ –¥–µ–ª–∞—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –ü–û–ò–°–ö –í–´–ë–†–û–°–û–í ===\n",
    "\n",
    "def find_outliers(df, col):\n",
    "    \"\"\"–ù–∞—Ö–æ–¥–∏—Ç –≤—ã–±—Ä–æ—Å—ã –ø–æ –º–µ—Ç–æ–¥—É IQR\"\"\"\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower) | (df[col] > upper)]\n",
    "    return len(outliers), lower, upper\n",
    "\n",
    "num_cols = train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print('üîç –í–´–ë–†–û–°–´:')\n",
    "for col in num_cols:\n",
    "    n_outliers, lower, upper = find_outliers(train, col)\n",
    "    if n_outliers > 0:\n",
    "        pct = n_outliers / len(train) * 100\n",
    "        print(f'{col}: {n_outliers} –≤—ã–±—Ä–æ—Å–æ–≤ ({pct:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å –≤—ã–±—Ä–æ—Å–∞–º–∏?**\n",
    "\n",
    "| –°–∏—Ç—É–∞—Ü–∏—è | –î–µ–π—Å—Ç–≤–∏–µ |\n",
    "|----------|----------|\n",
    "| –Ø–≤–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö | –£–¥–∞–ª–∏—Ç—å –∏–ª–∏ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ NaN |\n",
    "| –†–µ–∞–ª—å–Ω—ã–µ —Ä–µ–¥–∫–∏–µ —Å–ª—É—á–∞–∏ | –û—Å—Ç–∞–≤–∏—Ç—å, –º–æ–¥–µ–ª—å —Å–ø—Ä–∞–≤–∏—Ç—Å—è |\n",
    "| –ú–Ω–æ–≥–æ –≤—ã–±—Ä–æ—Å–æ–≤ (>5%) | –ü–æ–¥—É–º–∞–π –æ winsorization (–æ–±—Ä–µ–∑–∞—Ç—å —Ö–≤–æ—Å—Ç—ã) |\n",
    "\n",
    "**–í–∞–∂–Ω–æ:** –ë—É—Å—Ç–∏–Ω–≥–∏ (CatBoost, LightGBM) –æ–±—ã—á–Ω–æ —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –≤—ã–±—Ä–æ—Å–∞–º–∏!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "GROUPBY: –ì–ª–∞–≤–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "**Groupby –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã:**\n",
    "- –ö–∞–∫ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ X –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≥—Ä—É–ø–ø?\n",
    "- –í –∫–∞–∫–æ–π –≥—Ä—É–ø–ø–µ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ Y?\n",
    "- –ö–∞–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω —Ç–∞—Ä–≥–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GROUPBY –ü–†–ò–ú–ï–†–´ ===\n",
    "\n",
    "# –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫, –ø–æ—Å–º–æ—Ç—Ä–∏–º —Å—Ä–µ–¥–Ω–∏–π —Ç–∞—Ä–≥–µ—Ç –ø–æ –≥—Ä—É–ø–ø–∞–º\n",
    "cat_col = cat_cols[0] if cat_cols else None  # –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π\n",
    "\n",
    "if cat_col and train[TARGET].dtype in ['int64', 'float64']:\n",
    "    print(f'üìä –°—Ä–µ–¥–Ω–∏–π {TARGET} –ø–æ –≥—Ä—É–ø–ø–∞–º {cat_col}:')\n",
    "    grouped = train.groupby(cat_col)[TARGET].agg(['mean', 'count', 'std'])\n",
    "    grouped = grouped.sort_values('mean', ascending=False)\n",
    "    print(grouped)\n",
    "    print()\n",
    "    print('üí° –ï—Å–ª–∏ —Å—Ä–µ–¥–Ω–∏–µ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è ‚Äî —ç—Ç–æ—Ç –ø—Ä–∏–∑–Ω–∞–∫ –≤–∞–∂–µ–Ω!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –ü–û–õ–ï–ó–ù–´–ï GROUPBY –ü–ê–¢–¢–ï–†–ù–´ ===\n",
    "\n",
    "# 1. –°—Ä–µ–¥–Ω–µ–µ –ø–æ –≥—Ä—É–ø–ø–∞–º\n",
    "# train.groupby('category')['value'].mean()\n",
    "\n",
    "# 2. –ù–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ —Å—Ä–∞–∑—É\n",
    "# train.groupby('category')['value'].agg(['mean', 'median', 'std', 'count'])\n",
    "\n",
    "# 3. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∫–æ–ª–æ–Ω–∫–∞–º\n",
    "# train.groupby(['cat1', 'cat2'])['value'].mean()\n",
    "\n",
    "# 4. –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ä–∞–∑–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∫ —Ä–∞–∑–Ω—ã–º –∫–æ–ª–æ–Ω–∫–∞–º\n",
    "# train.groupby('category').agg({'col1': 'mean', 'col2': 'sum', 'col3': 'count'})\n",
    "\n",
    "# 5. Transform ‚Äî –≤–µ—Ä–Ω—É—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–π –∂–µ –¥–ª–∏–Ω—ã (–¥–ª—è feature engineering!)\n",
    "# train['group_mean'] = train.groupby('category')['value'].transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "FEATURE ENGINEERING –ù–ê –û–°–ù–û–í–ï EDA\n",
    "\n",
    "**–ò–¥–µ–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–≥–æ, —á—Ç–æ –º—ã —É–≤–∏–¥–µ–ª–∏:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FEATURE ENGINEERING ===\n",
    "\n",
    "def smart_fe(df, cat_cols, num_cols):\n",
    "    \"\"\"–£–º–Ω—ã–π feature engineering –Ω–∞ –æ—Å–Ω–æ–≤–µ EDA\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. –ê–≥—Ä–µ–≥–∞—Ç—ã –ø–æ –≥—Ä—É–ø–ø–∞–º (target encoding lite)\n",
    "    for cat in cat_cols[:3]:  # —Ç–æ–ø-3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö\n",
    "        for num in num_cols[:3]:  # —Ç–æ–ø-3 —á–∏—Å–ª–æ–≤—ã—Ö\n",
    "            df[f'{cat}_{num}_mean'] = df.groupby(cat)[num].transform('mean')\n",
    "    \n",
    "    # 2. –û—Ç–Ω–æ—à–µ–Ω–∏—è –º–µ–∂–¥—É —á–∏—Å–ª–æ–≤—ã–º–∏\n",
    "    if len(num_cols) >= 2:\n",
    "        df['ratio_0_1'] = df[num_cols[0]] / (df[num_cols[1]] + 1)\n",
    "        df['diff_0_1'] = df[num_cols[0]] - df[num_cols[1]]\n",
    "    \n",
    "    # 3. –°—á—ë—Ç—á–∏–∫ —Ä–µ–¥–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n",
    "    for cat in cat_cols:\n",
    "        counts = df[cat].value_counts()\n",
    "        df[f'{cat}_count'] = df[cat].map(counts)\n",
    "        df[f'{cat}_is_rare'] = (df[f'{cat}_count'] < 10).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º\n",
    "# train = smart_fe(train, cat_cols, num_cols)\n",
    "# test = smart_fe(test, cat_cols, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–ß–ï–ö–õ–ò–°–¢: –ß—Ç–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏\n",
    "\n",
    "‚úÖ –ü–æ–Ω—è–ª, —á—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è/—Ä–µ–≥—Ä–µ—Å—Å–∏—è)  \n",
    "‚úÖ –ü—Ä–æ–≤–µ—Ä–∏–ª –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤  \n",
    "‚úÖ –ü–æ—Å–º–æ—Ç—Ä–µ–ª –ø—Ä–æ–ø—É—Å–∫–∏  \n",
    "‚úÖ –ù–∞—à—ë–ª –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º  \n",
    "‚úÖ –ü—Ä–æ–≤–µ—Ä–∏–ª –Ω–∞ –ª–∏–∫–∏ (—Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è)  \n",
    "‚úÖ –ü–æ—Å–º–æ—Ç—Ä–µ–ª –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏  \n",
    "‚úÖ –ü—Ä–æ–≤–µ—Ä–∏–ª, —á—Ç–æ –≤ test –Ω–µ—Ç –Ω–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π  \n",
    "‚úÖ –ü–æ–¥—É–º–∞–ª –æ feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "–î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø –ë–ï–ó –ì–£–ì–õ–ê\n",
    "\n",
    "–ö–∞–∫ —Å–º–æ—Ç—Ä–µ—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø—Ä—è–º–æ –≤ Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–ø–æ—Å–æ–± 1: –ó–Ω–∞–∫ –≤–æ–ø—Ä–æ—Å–∞\n",
    "# pd.read_csv?\n",
    "\n",
    "# –°–ø–æ—Å–æ–± 2: –î–≤–∞ –∑–Ω–∞–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ (–∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥)\n",
    "# pd.read_csv??\n",
    "\n",
    "# –°–ø–æ—Å–æ–± 3: help()\n",
    "# help(pd.read_csv)\n",
    "\n",
    "# –°–ø–æ—Å–æ–± 4: dir() ‚Äî —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤ –æ–±—ä–µ–∫—Ç–∞\n",
    "# dir(train)  # –≤—Å–µ –º–µ—Ç–æ–¥—ã DataFrame\n",
    "# [m for m in dir(train) if not m.startswith('_')]  # –±–µ–∑ –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
