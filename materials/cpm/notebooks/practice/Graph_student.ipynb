{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07beef10",
      "metadata": {
        "id": "07beef10"
      },
      "source": [
        "# Исследуем идеи алгоритма PageRank\n",
        "\n",
        "Есть набор веб-страниц одного сайта.  \n",
        "У каждой страницы есть URL вида `https://www.site.com/p/<id>`.  \n",
        "Внутри текста страниц встречаются ссылки на другие страницы того же сайта — в том же формате URL. К сожалению, сайт взломали и добавили бессмысленные спам-страницы, нарушающие корректность переходов между страницами. Мы успели вручную проверить часть страниц и хотим на их основе разобраться с оставшимися.\n",
        "\n",
        "Таким образом реализуем упрощённый пайплайн индексатора:\n",
        "\n",
        "1) извлекаем ссылки из текста и строим ориентированный граф ссылок;\n",
        "2) получаем графовые признаки страниц:\n",
        "   - **доступность** страниц относительно некоторого верифицированного ядра страниц (seed pages),\n",
        "   - наличие **циклических ссылок**,\n",
        "   - глобальную «карту переходов» на малом поднаборе;\n",
        "3) на основе признаков построить **TrustScore** страницы;\n",
        "4) на небольшом поднаборе страниц построить kNN «похожие страницы по навигации»\n",
        "   (ближайшие по числу переходов по ссылкам).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0db3813",
      "metadata": {
        "id": "f0db3813"
      },
      "source": [
        "## Почему граф\n",
        "\n",
        "Ссылка внутри текста — это наблюдаемое действие автора страницы: он явно показывает, куда стоит перейти за уточнением, примером или продолжением.\n",
        "\n",
        "Мы используем сам факт ссылочного перехода как сигнал связи между страницами и строим ориентированный граф:\n",
        "- вершина — страница\n",
        "- ребро `u → v` — на странице `u` встречается ссылка на `v`\n",
        "\n",
        "Дальше мы исследуем структуру сайта как граф и получаем свойства страниц, которые невозможно извлечь из текста по отдельности.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39d75543",
      "metadata": {
        "id": "39d75543"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from typing import List, Dict, Tuple\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba776e70",
      "metadata": {
        "id": "ba776e70"
      },
      "source": [
        "## Данные\n",
        "\n",
        "Мы будем работать с синтетическим датасетом `pages.csv`.\n",
        "Если файла нет, он будет сгенерирован локально.\n",
        "\n",
        "В генераторе есть:\n",
        "- `is_seed`: доверенные страницы (ядро)\n",
        "- `is_spam`: страницы, которые чаще образуют “фермы ссылок” (замкнутые структуры)\n",
        "\n",
        "Эти поля нужны для эксперимента с TrustScore в конце.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad103305",
      "metadata": {
        "id": "ad103305"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_url(i: int) -> str:\n",
        "    return f\"https://www.site.com/p/{i}\"\n",
        "\n",
        "def generate_pages(\n",
        "    n_pages: int = 200,\n",
        "    vocab_size: int = 300,\n",
        "    words_per_page: Tuple[int, int] = (80, 160),\n",
        "    links_per_page: Tuple[int, int] = (2, 8),\n",
        "    n_seed: int = 8,\n",
        "    n_spam_clusters: int = 3,\n",
        "    spam_cluster_size: int = 10,\n",
        "    seed: int = 42,\n",
        "    out_csv: str = \"pages.csv\",\n",
        ") -> None:\n",
        "    \"\"\"Генератор синтетических страниц с ссылками в тексте.\"\"\"\n",
        "    rnd = random.Random(seed)\n",
        "    vocab = [f\"word{j}\" for j in range(vocab_size)]\n",
        "\n",
        "    urls = [make_url(i) for i in range(n_pages)]\n",
        "    seed_ids = set(rnd.sample(range(n_pages), n_seed))\n",
        "\n",
        "    # создаём “спам-кластеры” (циклические ссылки)\n",
        "    spam_nodes = set()\n",
        "    clusters = []\n",
        "    candidates = [i for i in range(n_pages) if i not in seed_ids]\n",
        "    rnd.shuffle(candidates)\n",
        "    ptr = 0\n",
        "    for _ in range(n_spam_clusters):\n",
        "        cluster = candidates[ptr:ptr + spam_cluster_size]\n",
        "        ptr += spam_cluster_size\n",
        "        if len(cluster) == spam_cluster_size:\n",
        "            clusters.append(cluster)\n",
        "            spam_nodes.update(cluster)\n",
        "\n",
        "    rows = []\n",
        "    for i in range(n_pages):\n",
        "        n_words = rnd.randint(*words_per_page)\n",
        "        words = [rnd.choice(vocab) for _ in range(n_words)]\n",
        "\n",
        "        n_links = rnd.randint(*links_per_page)\n",
        "        out = []\n",
        "\n",
        "        if i in spam_nodes:\n",
        "            cluster = next(c for c in clusters if i in c)\n",
        "            out.append(rnd.choice(cluster))\n",
        "            while len(out) < n_links:\n",
        "                if rnd.random() < 0.85:\n",
        "                    out.append(rnd.choice(cluster))\n",
        "                else:\n",
        "                    out.append(rnd.randrange(n_pages))\n",
        "        else:\n",
        "            while len(out) < n_links:\n",
        "                r = rnd.random()\n",
        "                if r < 0.25:\n",
        "                    out.append(rnd.choice(list(seed_ids)))\n",
        "                else:\n",
        "                    out.append(rnd.randrange(n_pages))\n",
        "\n",
        "        # вставляем URL прямо в текст (как токены)\n",
        "        for v in out:\n",
        "            pos = rnd.randrange(len(words) + 1)\n",
        "            words.insert(pos, make_url(v))\n",
        "\n",
        "        rows.append({\n",
        "            \"page_id\": i,\n",
        "            \"url\": urls[i],\n",
        "            \"is_seed\": int(i in seed_ids),\n",
        "            \"is_spam\": int(i in spam_nodes),\n",
        "            \"text\": \" \".join(words),\n",
        "        })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(out_csv, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"pages.csv\"):\n",
        "    generate_pages()\n",
        "\n",
        "df = pd.read_csv(\"pages.csv\")\n",
        "\n",
        "required = {\"page_id\", \"url\", \"is_seed\", \"is_spam\", \"text\"}"
      ],
      "metadata": {
        "id": "bvPNheia9ET3"
      },
      "id": "bvPNheia9ET3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert required.issubset(df.columns), f\"Missing columns: {required - set(df.columns)}\"\n",
        "assert df[\"page_id\"].is_unique\n",
        "assert df[\"page_id\"].min() == 0\n",
        "assert df[\"page_id\"].max() == len(df) - 1"
      ],
      "metadata": {
        "id": "qyyM-VVm9Gl0"
      },
      "id": "qyyM-VVm9Gl0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2tiG21Wd9H-T"
      },
      "id": "2tiG21Wd9H-T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "90a51186",
      "metadata": {
        "id": "90a51186"
      },
      "source": [
        "## Шаг 1. Извлечь ссылки из текста\n",
        "\n",
        "Ссылки имеют формат `https://www.site.com/p/<id>`.\n",
        "Мы извлекаем все такие ссылки из текста каждой страницы и получаем список исходящих ссылок `out_links`.\n",
        "\n",
        "Дальше именно `out_links` станет основой для построения графа.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "171abfba",
      "metadata": {
        "id": "171abfba"
      },
      "outputs": [],
      "source": [
        "\n",
        "URL_RE = re.compile(r\"https://www\\.site\\.com/p/(\\d+)\")\n",
        "\n",
        "def extract_out_links(text: str) -> List[int]:\n",
        "    \"\"\"TODO: извлечь из текста все id страниц, на которые есть ссылка.\"\"\"\n",
        "    # Подсказка: URL_RE.findall(text) вернёт список строковых чисел.\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def unique_in_range(xs: List[int], n: int) -> List[int]:\n",
        "    \"\"\"TODO: убрать дубликаты, сохранить порядок, выбросить ссылки вне диапазона [0, n-1].\"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "n = len(df)\n",
        "df = df.copy()\n",
        "df[\"out_links_raw\"] = df[\"text\"].astype(str).map(extract_out_links)\n",
        "df[\"out_links\"] = df[\"out_links_raw\"].map(lambda xs: unique_in_range(xs, n))\n",
        "\n",
        "# проверки\n",
        "assert df[\"out_links_raw\"].map(lambda x: isinstance(x, list)).all()\n",
        "assert df[\"out_links_raw\"].map(lambda xs: all(isinstance(v, int) for v in xs)).all()\n",
        "assert df[\"out_links\"].map(lambda xs: all(0 <= v < n for v in xs)).all()\n",
        "\n",
        "df[[\"page_id\", \"out_links\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19c5348a",
      "metadata": {
        "id": "19c5348a"
      },
      "source": [
        "## Шаг 2. Построить граф ссылок\n",
        "\n",
        "Мы будем использовать два представления одного графа:\n",
        "\n",
        "- **Список смежности**: для каждой страницы список страниц, на которые она ссылается.\n",
        "  Это удобно для обходов и локального анализа.\n",
        "- **Матрица смежности**: `A[u, v] = 1`, если есть ссылка `u → v`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecaed772",
      "metadata": {
        "id": "ecaed772"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e1048c",
      "metadata": {
        "id": "27e1048c"
      },
      "outputs": [],
      "source": [
        "def build_adj_list(df: pd.DataFrame) -> List[List[int]]:\n",
        "    \"\"\"TODO: построить список смежности по df['out_links']\"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def build_adj_matrix(adj: List[List[int]]) -> np.ndarray:\n",
        "    \"\"\"TODO: построить матрицу смежности A (0/1) по списку смежности.\"\"\"\n",
        "    raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj = build_adj_list(df)\n",
        "A = build_adj_matrix(adj)"
      ],
      "metadata": {
        "id": "uVdppA-19OO-"
      },
      "id": "uVdppA-19OO-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert isinstance(adj, list) and len(adj) == n\n",
        "assert isinstance(A, np.ndarray) and A.shape == (n, n)\n",
        "assert set(np.unique(A)).issubset({0, 1})"
      ],
      "metadata": {
        "id": "91g3zIaQ9POj"
      },
      "id": "91g3zIaQ9POj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# базовые степени\n",
        "out_degree = np.array([len(vs) for vs in adj], dtype=int)\n",
        "in_degree = A.sum(axis=0).astype(int)\n",
        "\n",
        "df[\"out_degree\"] = out_degree\n",
        "df[\"in_degree\"] = in_degree"
      ],
      "metadata": {
        "id": "X1PlsxBx9SMa"
      },
      "id": "X1PlsxBx9SMa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"page_id\", \"in_degree\", \"out_degree\"]].head()"
      ],
      "metadata": {
        "id": "5f49umK09Ttg"
      },
      "id": "5f49umK09Ttg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1a260fde",
      "metadata": {
        "id": "1a260fde"
      },
      "source": [
        "## Шаг 3. Доступность доверенного ядра (расстояния по ссылкам)\n",
        "\n",
        "На сайте обычно есть набор страниц, которым можно доверять заранее (seed pages).\n",
        "Мы хотим измерить **сколько шагов по ссылкам** отделяет каждую страницу от доверенного ядра.\n",
        "\n",
        "Интерпретация простая: чем меньше переходов нужно, чтобы попасть к доверенным страницам,\n",
        "тем “ближе” страница к здоровой структуре сайта.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "559f334b",
      "metadata": {
        "id": "559f334b"
      },
      "outputs": [],
      "source": [
        "\n",
        "from collections import deque\n",
        "import math\n",
        "\n",
        "def reverse_graph(adj: List[List[int]]) -> List[List[int]]:\n",
        "    \"\"\"TODO: построить обратный граф.\"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def dist_to_seeds_by_links(adj: List[List[int]], seeds: List[int]) -> List[float]:\n",
        "    \"\"\"TODO: расстояние (число переходов) от каждой страницы ДО множества seed-страниц.\n",
        "\n",
        "    Рекомендация: удобнее считать BFS по обратному графу, стартуя из seeds.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seeds = df.loc[df[\"is_seed\"] == 1, \"page_id\"].tolist()\n",
        "dist_seed = dist_to_seeds_by_links(adj, seeds)\n",
        "\n",
        "df[\"dist_to_seed\"] = dist_seed\n",
        "df[\"reachable_3\"] = [d <= 3 for d in dist_seed]\n",
        "df[\"reachable_5\"] = [d <= 5 for d in dist_seed]"
      ],
      "metadata": {
        "id": "Nn5TN9dB9hZh"
      },
      "id": "Nn5TN9dB9hZh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert df[\"dist_to_seed\"].map(lambda x: (x == math.inf) or (isinstance(x, (int, float)) and x >= 0)).all()"
      ],
      "metadata": {
        "id": "2A5Vd40x9jRe"
      },
      "id": "2A5Vd40x9jRe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"page_id\", \"is_seed\", \"dist_to_seed\", \"reachable_3\", \"reachable_5\"]].head()"
      ],
      "metadata": {
        "id": "U5D8Fueo9krn"
      },
      "id": "U5D8Fueo9krn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "41b51120",
      "metadata": {
        "id": "41b51120"
      },
      "source": [
        "## Шаг 4. Петли и замкнутые области (циклы)\n",
        "\n",
        "Если переходя по ссылкам можно вернуться к уже посещённой странице,\n",
        "значит в графе есть замкнутая структура.\n",
        "\n",
        "В документации и навигации такие области часто сигнализируют о проблемах, например если теорема 1 доказыватся через теорему 2, а теорема 2 доказывается через теорему 1, то на лицо явная проблема в логике. С страницами абсолютно тоже самое.\n",
        "\n",
        "Поэтому мы добавим признак `in_cycle`: участвует ли страница хотя бы в одной петле.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "562a8de8",
      "metadata": {
        "id": "562a8de8"
      },
      "outputs": [],
      "source": [
        "def in_any_cycle(adj: List[List[int]]) -> List[bool]:\n",
        "    \"\"\"TODO: вернуть список длины N: True, если вершина участвует хотя бы в одном цикле.\n",
        "\n",
        "    Можно реализовать через DFS со стеком рекурсии (цвета 0/1/2).\n",
        "    \"\"\"\n",
        "    raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"in_cycle\"] = in_any_cycle(adj)\n",
        "assert df[\"in_cycle\"].map(lambda x: isinstance(x, bool)).all()"
      ],
      "metadata": {
        "id": "rExXOMMC9pHv"
      },
      "id": "rExXOMMC9pHv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"page_id\", \"in_cycle\"]].head()"
      ],
      "metadata": {
        "id": "Lgg2yCB59qQa"
      },
      "id": "Lgg2yCB59qQa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "89629c1e",
      "metadata": {
        "id": "89629c1e"
      },
      "source": [
        "## Шаг 5. Карта навигации на малом поднаборе (полные попарные расстояния)\n",
        "\n",
        "Построение полной матрицы расстояний для всех страниц обычно слишком дорогое по ассимптотике.\n",
        "Поэтому мы берём небольшой поднабор важных страниц (например, seed + страницы с высоким in-degree)\n",
        "и строим для него матрицу переходов: минимальное число переходов между любой парой.\n",
        "\n",
        "Эта матрица позволяет:\n",
        "- оценить, какие страницы составляют центр кластеров (в среднем ближе к другим),\n",
        "- строить навигационные рекомендации: k ближайших страниц по числу переходов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d5ef94a",
      "metadata": {
        "id": "6d5ef94a"
      },
      "outputs": [],
      "source": [
        "INF = 10**9\n",
        "\n",
        "def choose_subset(df: pd.DataFrame, max_p: int = 180) -> List[int]:\n",
        "    \"\"\"Готовая функция выбора поднабора (не является целью задания).\"\"\"\n",
        "    seed_pages = df.loc[df[\"is_seed\"] == 1, \"page_id\"].tolist()\n",
        "    top = df.sort_values(\"in_degree\", ascending=False)[\"page_id\"].tolist()\n",
        "\n",
        "    picked = []\n",
        "    seen = set()\n",
        "    for x in seed_pages + top:\n",
        "        x = int(x)\n",
        "        if x not in seen:\n",
        "            picked.append(x)\n",
        "            seen.add(x)\n",
        "        if len(picked) >= max_p:\n",
        "            break\n",
        "    return picked"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P = choose_subset(df, max_p=180)\n",
        "P_set = set(P)\n",
        "idx = {pid: i for i, pid in enumerate(P)}\n",
        "m = len(P)\n",
        "assert m <= 180"
      ],
      "metadata": {
        "id": "PYb2a_pA-Sj-"
      },
      "id": "PYb2a_pA-Sj-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dist_matrix_on_subset(adj: List[List[int]], P: List[int]) -> np.ndarray:\n",
        "    \"\"\"TODO: построить матрицу dist0 на поднаборе P:\n",
        "    - dist0[i,i]=0\n",
        "    - dist0[i,j]=1 если есть ребро (P[i] -> P[j])\n",
        "    - иначе INF\n",
        "    \"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def floyd_warshall(dist0: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"TODO: алгоритм Флойда–Уоршелла для матрицы dist0.\"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def graph_knn_from_dist(dist: np.ndarray, k: int) -> List[List[int]]:\n",
        "    \"\"\"TODO: для каждой вершины i вернуть k ближайших j (по dist[i,j]), исключая i и INF.\"\"\"\n",
        "    raise NotImplementedError"
      ],
      "metadata": {
        "id": "UWmfKR8K-UwH"
      },
      "id": "UWmfKR8K-UwH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D0 = build_dist_matrix_on_subset(adj, P)\n",
        "D = floyd_warshall(D0)\n",
        "knn_idx = graph_knn_from_dist(D, k=5)\n",
        "knn_pages = [[P[j] for j in neigh] for neigh in knn_idx]"
      ],
      "metadata": {
        "id": "4RMxLm-w-WAi"
      },
      "id": "4RMxLm-w-WAi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert D.shape == (m, m)\n",
        "assert (np.diag(D) == 0).all()\n",
        "assert len(knn_pages) == m"
      ],
      "metadata": {
        "id": "cvkSHAjr-YU_"
      },
      "id": "cvkSHAjr-YU_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cd46ec1a",
      "metadata": {
        "id": "cd46ec1a"
      },
      "source": [
        "### Признаки из карты навигации (на поднаборе)\n",
        "\n",
        "По матрице расстояний можно получить простые агрегаты:\n",
        "- среднее расстояние до достижимых страниц (proxy “центральности”)\n",
        "- расстояние до ближайшего seed (если seed входит в поднабор)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed38d4dd",
      "metadata": {
        "id": "ed38d4dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "avg_dist = []\n",
        "min_dist_to_seed = []\n",
        "\n",
        "seed_in_P = [idx[s] for s in df.loc[df[\"is_seed\"] == 1, \"page_id\"].tolist() if s in idx]\n",
        "\n",
        "for i in range(m):\n",
        "    row = D[i]\n",
        "    finite = row[row < INF]\n",
        "    avg_dist.append(float(finite.mean()) if len(finite) else float(\"inf\"))\n",
        "    if seed_in_P:\n",
        "        min_dist_to_seed.append(int(row[seed_in_P].min()))\n",
        "    else:\n",
        "        min_dist_to_seed.append(INF)\n",
        "\n",
        "df[\"avg_dist_in_subset\"] = np.nan\n",
        "df[\"min_dist_to_seed_in_subset\"] = np.nan\n",
        "df[\"knn_pages_in_subset\"] = None\n",
        "\n",
        "for i, pid in enumerate(P):\n",
        "    df.loc[df[\"page_id\"] == pid, \"avg_dist_in_subset\"] = avg_dist[i]\n",
        "    df.loc[df[\"page_id\"] == pid, \"min_dist_to_seed_in_subset\"] = min_dist_to_seed[i]\n",
        "    df.loc[df[\"page_id\"] == pid, \"knn_pages_in_subset\"] = str(knn_pages[i])\n",
        "\n",
        "df.loc[df[\"page_id\"].isin(P), [\"page_id\", \"avg_dist_in_subset\", \"min_dist_to_seed_in_subset\", \"knn_pages_in_subset\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02f5bac8",
      "metadata": {
        "id": "02f5bac8"
      },
      "source": [
        "## Дополнение: достижимость за ≤ K шагов (булева матричная степень)\n",
        "\n",
        "Иногда важно не точное расстояние, а факт: можно ли добраться за не более чем K переходов.\n",
        "Это отражает реальное UX-ограничение: пользователь редко делает много кликов подряд.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc6097e",
      "metadata": {
        "id": "7dc6097e"
      },
      "outputs": [],
      "source": [
        "def reachability_upto_k(A_bool: np.ndarray, K: int) -> np.ndarray:\n",
        "    \"\"\"Готово: R[i,j]=True, если существует путь длины <= K.\"\"\"\n",
        "    assert A_bool.dtype == bool\n",
        "    R = A_bool.copy()\n",
        "    P = A_bool.copy()\n",
        "    for _ in range(2, K + 1):\n",
        "        P = (P @ A_bool)\n",
        "        R = R | P\n",
        "    return R\n",
        "\n",
        "# пример на поднаборе\n",
        "A_sub = (D0 == 1)\n",
        "R_le_3 = reachability_upto_k(A_sub, K=3)\n",
        "assert R_le_3.shape == (m, m)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f585cba0",
      "metadata": {
        "id": "f585cba0"
      },
      "source": [
        "## Шаг 6. TrustScore как ML-задача\n",
        "\n",
        "У страницы нет одного признака, который надёжно определяет доверие.\n",
        "Например, высокая входящая степень бывает и у справки, и у мусорной страницы.\n",
        "Поэтому мы комбинируем несколько сигналов и обучаем простую модель.\n",
        "\n",
        "В генераторе есть синтетическая разметка:\n",
        "- `is_seed=1` считаем “доверенной” страницей\n",
        "- `is_spam=1` считаем “недоверенной”\n",
        "\n",
        "Остальные страницы в обучение не берём — они остаются для предсказания.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2250289e",
      "metadata": {
        "id": "2250289e"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "df = df.copy()\n",
        "df[\"trust_label\"] = np.where(df[\"is_seed\"] == 1, 1, np.where(df[\"is_spam\"] == 1, 0, np.nan))\n",
        "\n",
        "feature_cols = [\n",
        "    \"in_degree\",\n",
        "    \"out_degree\",\n",
        "    \"dist_to_seed\",\n",
        "    \"reachable_3\",\n",
        "    \"reachable_5\",\n",
        "    \"in_cycle\",\n",
        "    \"avg_dist_in_subset\",\n",
        "    \"min_dist_to_seed_in_subset\",\n",
        "]\n",
        "\n",
        "work = df.copy()\n",
        "\n",
        "# чистим inf/NaN\n",
        "work[\"dist_to_seed\"] = work[\"dist_to_seed\"].replace([np.inf], np.nan)\n",
        "work[\"dist_to_seed\"] = work[\"dist_to_seed\"].fillna(work[\"dist_to_seed\"].max() + 1)\n",
        "\n",
        "work[\"avg_dist_in_subset\"] = work[\"avg_dist_in_subset\"].fillna(work[\"avg_dist_in_subset\"].median())\n",
        "work[\"min_dist_to_seed_in_subset\"] = work[\"min_dist_to_seed_in_subset\"].fillna(work[\"min_dist_to_seed_in_subset\"].median())\n",
        "\n",
        "# bool -> int\n",
        "for c in [\"reachable_3\", \"reachable_5\", \"in_cycle\"]:\n",
        "    work[c] = work[c].astype(int)\n",
        "\n",
        "labeled = work.dropna(subset=[\"trust_label\"]).copy()\n",
        "X = labeled[feature_cols].to_numpy(dtype=float)\n",
        "y = labeled[\"trust_label\"].astype(int).to_numpy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42, stratify=y)\n",
        "\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "proba_test = model.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, proba_test)\n",
        "auc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b050ecf",
      "metadata": {
        "id": "9b050ecf"
      },
      "source": [
        "## Результат\n",
        "\n",
        "- `trust_score` — оценка доверия страницы по структуре ссылок (и производным признакам)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b55acf6",
      "metadata": {
        "id": "9b55acf6"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_all = work[feature_cols].to_numpy(dtype=float)\n",
        "work[\"trust_score\"] = model.predict_proba(X_all)[:, 1]\n",
        "\n",
        "# 10 самых подозрительных (низкий trust_score), среди не-seed\n",
        "work[work[\"is_seed\"] == 0].sort_values(\"trust_score\").head(10)[\n",
        "    [\"page_id\", \"trust_score\", \"is_spam\", \"in_cycle\", \"dist_to_seed\", \"in_degree\", \"out_degree\"]\n",
        "]\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}